{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning Project - Master MALIA  \n",
    "\n",
    "Done by : Mohammed Ali EL ADLOUNI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "# Change to the directory where the script is located\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "seed = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 0\n",
    "train_data_dataset_0   = np.load(r'../dataset/train/dataset_0/kaggle_source_cate_0_train.npy')\n",
    "train_labels_dataset_0 = np.load(r'../dataset/train/dataset_0/kaggle_source_cate_0_train_label.npy')\n",
    "test_data_dataset_0    = np.load(r'../dataset/test/dataset_0/kaggle_source_cate_0_test.npy')\n",
    "test_labels_dataset_0  = np.load(r'../dataset/test/dataset_0/kaggle_source_cate_0_test_label.npy')\n",
    "\n",
    "# dataset 1\n",
    "train_data_dataset_1   = np.load(r'../dataset/train/dataset_1/kaggle_source_cate_1_train.npy')\n",
    "train_labels_dataset_1 = np.load(r'../dataset/train/dataset_1/kaggle_source_cate_1_train_label.npy')\n",
    "test_data_dataset_1    = np.load(r'../dataset/test/dataset_1/kaggle_source_cate_1_test.npy')\n",
    "test_labels_dataset_1  = np.load(r'../dataset/test/dataset_1/kaggle_source_cate_1_test_label.npy')\n",
    "\n",
    "# dataset 2\n",
    "train_data_dataset_2   = np.load(r'../dataset/train/dataset_2/kaggle_source_cate_2_train.npy')\n",
    "train_labels_dataset_2 = np.load(r'../dataset/train/dataset_2/kaggle_source_cate_2_train_label.npy')\n",
    "test_data_dataset_2    = np.load(r'../dataset/test/dataset_2/kaggle_source_cate_2_test.npy')\n",
    "test_labels_dataset_2  = np.load(r'../dataset/test/dataset_2/kaggle_source_cate_2_test_label.npy')\n",
    "\n",
    "# dataset 3\n",
    "train_data_dataset_3   = np.load(r'../dataset/train/dataset_3/kaggle_source_cate_3_train.npy')\n",
    "train_labels_dataset_3 = np.load(r'../dataset/train/dataset_3/kaggle_source_cate_3_train_label.npy')\n",
    "test_data_dataset_3    = np.load(r'../dataset/test/dataset_3/kaggle_source_cate_3_test.npy')\n",
    "test_labels_dataset_3  = np.load(r'../dataset/test/dataset_3/kaggle_source_cate_3_test_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0:\n",
      "  Train data:  (41058, 51)\n",
      "  Train labels:(41058, 2)\n",
      "  Test data:   (13686, 51)\n",
      "  Test labels: (13686, 2)\n",
      "----------------------------------------\n",
      "Dataset 1:\n",
      "  Train data:  (41058, 51)\n",
      "  Train labels:(41058, 2)\n",
      "  Test data:   (13686, 51)\n",
      "  Test labels: (13686, 2)\n",
      "----------------------------------------\n",
      "Dataset 2:\n",
      "  Train data:  (41058, 51)\n",
      "  Train labels:(41058, 2)\n",
      "  Test data:   (13686, 51)\n",
      "  Test labels: (13686, 2)\n",
      "----------------------------------------\n",
      "Dataset 3:\n",
      "  Train data:  (41058, 51)\n",
      "  Train labels:(41058, 2)\n",
      "  Test data:   (13686, 51)\n",
      "  Test labels: (13686, 2)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f\"Dataset {i}:\")\n",
    "    print(f\"  Train data:  {eval(f'train_data_dataset_{i}').shape}\")\n",
    "    print(f\"  Train labels:{eval(f'train_labels_dataset_{i}').shape}\")\n",
    "    print(f\"  Test data:   {eval(f'test_data_dataset_{i}').shape}\")\n",
    "    print(f\"  Test labels: {eval(f'test_labels_dataset_{i}').shape}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions for train_labels_dataset_0: {np.int64(0): np.float64(0.8995810804228165), np.int64(1): np.float64(0.10041891957718349)}\n",
      "Proportions for train_labels_dataset_1: {np.int64(0): np.float64(0.9004335330508062), np.int64(1): np.float64(0.09956646694919383)}\n",
      "Proportions for train_labels_dataset_2: {np.int64(0): np.float64(0.901675678308734), np.int64(1): np.float64(0.09832432169126601)}\n",
      "Proportions for train_labels_dataset_3: {np.int64(0): np.float64(0.9018461688343319), np.int64(1): np.float64(0.09815383116566807)}\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    var_name = f\"train_labels_dataset_{i}\"\n",
    "    calculate_proportions(eval(var_name), var_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets with both train and test data\n",
    "datasets = [\n",
    "    {\n",
    "        'X_train': train_data_dataset_0, \n",
    "        'y_train': train_labels_dataset_0[:,1], \n",
    "        'X_test': test_data_dataset_0, \n",
    "        'y_test': test_labels_dataset_0[:,1], \n",
    "        'sampling': 'none'  # No sampling\n",
    "    },\n",
    "    {\n",
    "        'X_train': train_data_dataset_1, \n",
    "        'y_train': train_labels_dataset_1[:,1], \n",
    "        'X_test': test_data_dataset_1, \n",
    "        'y_test': test_labels_dataset_1[:,1], \n",
    "        'sampling': 'undersampling'  # Undersampling\n",
    "    },\n",
    "    {\n",
    "        'X_train': train_data_dataset_2, \n",
    "        'y_train': train_labels_dataset_2[:,1], \n",
    "        'X_test': test_data_dataset_2, \n",
    "        'y_test': test_labels_dataset_2[:,1], \n",
    "        'sampling': 'oversampling'  # Oversampling\n",
    "    },\n",
    "    {\n",
    "        'X_train': train_data_dataset_3, \n",
    "        'y_train': train_labels_dataset_3[:,1], \n",
    "        'X_test': test_data_dataset_3, \n",
    "        'y_test': test_labels_dataset_3[:,1], \n",
    "        'sampling': 'cost_sensitive'  # Cost-sensitive learning\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the models\n",
    "models = ['Random Forest', 'Bagging', 'Boosting', 'Penalized Logistic Regression', 'Simple Decision Tree', 'XGBoost', 'Stacking']\n",
    "models = ['Simple Decision Tree', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel execution\n",
    "# Use joblib's Parallel and delayed to parallelize model runs\n",
    "results_list = Parallel(n_jobs=-1)(delayed(run_model_on_dataset)(model, dataset, i) \n",
    "                                   for i, dataset in enumerate(datasets) \n",
    "                                   for model in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results List: [{'dataset': 1, 'sampling': 'none', 'model': 'Simple Decision Tree', 'best_params': {'max_depth': 10}, 'F1 Score': 0.7112616426756986, 'Precision': 0.7932011331444759, 'Recall': 0.6446661550268611, 'Balanced accuracy': np.float64(0.8134903092020359), 'elapsed_time': 1.4602417945861816}, {'dataset': 1, 'sampling': 'none', 'model': 'XGBoost', 'best_params': {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3}, 'F1 Score': 0.7017225747960109, 'Precision': 0.8571428571428571, 'Recall': 0.5940138142747505, 'Balanced accuracy': np.float64(0.7917981532005264), 'elapsed_time': 3.4574952125549316}, {'dataset': 2, 'sampling': 'undersampling', 'model': 'Simple Decision Tree', 'best_params': {'max_depth': 10}, 'F1 Score': 0.543168880455408, 'Precision': 0.39784572619874914, 'Recall': 0.8557548579970105, 'Balanced accuracy': np.float64(0.8577041215802998), 'elapsed_time': 0.38431549072265625}, {'dataset': 2, 'sampling': 'undersampling', 'model': 'XGBoost', 'best_params': {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3}, 'F1 Score': 0.5845995364408962, 'Precision': 0.44597249508840864, 'Recall': 0.8482810164424515, 'Balanced accuracy': np.float64(0.8670462419432861), 'elapsed_time': 1.8039524555206299}, {'dataset': 3, 'sampling': 'oversampling', 'model': 'Simple Decision Tree', 'best_params': {'max_depth': 10}, 'F1 Score': 0.6771050800278358, 'Precision': 0.6552188552188553, 'Recall': 0.7005039596832253, 'Balanced accuracy': np.float64(0.8294338941296504), 'elapsed_time': 3.9862513542175293}, {'dataset': 3, 'sampling': 'oversampling', 'model': 'XGBoost', 'best_params': {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3}, 'F1 Score': 0.6803105151729005, 'Precision': 0.6671280276816609, 'Recall': 0.6940244780417567, 'Balanced accuracy': np.float64(0.8274546233422575), 'elapsed_time': 5.271892786026001}, {'dataset': 4, 'sampling': 'cost_sensitive', 'model': 'Simple Decision Tree', 'best_params': {'max_depth': 20}, 'F1 Score': 0.6664482306684142, 'Precision': 0.6141304347826086, 'Recall': 0.7285100286532952, 'Balanced accuracy': np.float64(0.838258269005248), 'elapsed_time': 1.7330522537231445}, {'dataset': 4, 'sampling': 'cost_sensitive', 'model': 'XGBoost', 'best_params': {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3}, 'F1 Score': 0.6184486373165619, 'Precision': 0.48760330578512395, 'Recall': 0.8452722063037249, 'Balanced accuracy': np.float64(0.8721885848442954), 'elapsed_time': 3.3617031574249268}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results List:\", results_list)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "#results_df.to_csv(r'results/results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble_learning_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
